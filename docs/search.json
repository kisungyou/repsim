[
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "The easiest way to install repsim is through official repositories such as PyPI and CRAN.\nThe development version can also be installed from source hosted on GitHub:"
  },
  {
    "objectID": "installation.html#dependencies",
    "href": "installation.html#dependencies",
    "title": "Installation",
    "section": "Dependencies",
    "text": "Dependencies\nrepsim is build on a shared C++17 computational backend, ensuring consistent performance across Python and R. To install and use repsim, your system should have\n\nA C++17-compatible compiler (e.g., GCC ≥ 9, Clang ≥ 10, or MSVC ≥ 2019)\nCMake ≥ 3.20 (required only when building from source)\nStandard build tools available on Linux, macOS, and Windows\n\nFor language-specific requirements, see below:\n\nPythonR\n\n\nRequires a modern Python environment (≥ 3.8) and the following build dependencies:\n\nscikit-build-core ≥ 0.10 - build backend integrating CMake with PEP 517\npybind11 ≥ 2.11 -Python/C++ interface\nnumpy ≥ 1.23 - array and numerical operations\npackaging ≥ 23.0 - version and metadata management\n\n\n\nRequires R ≥ 4.2 and a working C++17 toolchain. All necessary C++ headers (Rcpp, Eigen) are bundled and linked automatically and no additional R dependencies need to be installed manually."
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API Reference",
    "section": "",
    "text": "Welcome to the repsim API reference.\nThis section documents Python functions and utilities you can call directly. Use the left sidebar to navigate.\n\nAlignment\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlin_reg\nLinear Regression\n\n\n\n\n\n\nCCA\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncca\nCanonical Correlation Analysis\n\n\npwcca\nProjection-Weighted Canonical Correlation Analysis\n\n\nsvcca\nSingular Vector Canonical Correlation Analysis",
    "crumbs": [
      "Overview",
      "API Home"
    ]
  },
  {
    "objectID": "api/family_cca/CCA.html",
    "href": "api/family_cca/CCA.html",
    "title": "cca",
    "section": "",
    "text": "Description\nCanonical correlation analysis (CCA) aims at inferring information from cross-covariance matrices (Golub and Zha 1995). This function computes pairwise CCA-based similarities between multiple representations, summarized by either Yanai’s GCD measure (Ramsay, ten Berge, and Styan 1984) or Pillai’s trace statistic (Raghu et al. 2017).\n\n\nUsage\n\nPythonR\n\n\nrepsim.cca(mats, summary_type = None)\n\n\ncca(mats, summary_type = NULL)\n\n\n\n\n\nArguments\n\nPythonR\n\n\n\nmats: sequence of array-like, length \\(M\\) List or tuple of M data representations, each of shape (n_samples, n_features_k). All matrices must share the same number of rows for matching samples. Each element can be a NumPy array or any object convertible to one via numpy.asarray.\nsummary_type: str, optional Summary statistic for canonical correlations. One of \"yanai\" and \"pillai\". Defaults to \"yanai\".\n\n\n\n\nmats: A list of length M containing data matrices of size (n_samples, n_features_k). All matrices must share the same number of rows for matching samples.\nsummary_type: Character scalar indicating the CCA summary statistic. One of \"yanai\" or \"pillai\". Defaults to \"yanai\" if NULL.\n\n\n\n\n\n\nReturns\n\nPythonR\n\n\n\nnumpy.ndarray\n\nArray of shape (M, M) of CCA summary similarities.\n\n\n\n\n\nmatrix\n\nAn (M, M) symmetric matrix of CCA summary similarities.\n\n\n\n\n\n\n\nExamples\n\nPythonR\n\n\n\n# | cache: true\n# load necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nimport repsim\n\n# set a random seed\nnp.random.seed(1)\n\n# prepare the prototype\niris = load_iris(as_frame=True).frame.iloc[:, :4]\nurl = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv\"\nusarrests = pd.read_csv(url, index_col=0)\n\nX = StandardScaler().fit_transform(iris.sample(50, random_state=1))\nY = StandardScaler().fit_transform(usarrests)\n\nn, p_X, p_Y = X.shape[0], X.shape[1], Y.shape[1]\n\n# generate 10 of each by perturbation\nmats = []\nfor _ in range(10):\n    mats.append(X + np.random.normal(scale=1.0, size=(n, p_X)))\nfor _ in range(10):\n    mats.append(Y + np.random.normal(scale=1.0, size=(n, p_Y)))\n\n# compute similarities\ncca_gcd = repsim.cca(mats, summary_type=\"yanai\")\ncca_trace = repsim.cca(mats, summary_type=\"pillai\")\n\n# visualize: two heatmaps side by side\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\ntitles = [\"CCA: Yanai's GCD\", \"CCA: Pillai's Trace\"]\nmats_show = [cca_gcd, cca_trace]\n\nlabs = [f\"rep {i}\" for i in range(1, 21)]\neven_idx = list(range(1, 20, 2))\n\nfor ax, mat, title in zip(axes, mats_show, titles):\n    im = ax.imshow(mat, origin=\"upper\")\n    ax.set_title(title)\n    _ = ax.set_xticks(even_idx)\n    _ = ax.set_xticklabels([labs[i] for i in even_idx], rotation=90)\n    _ = ax.set_yticks(even_idx)\n    _ = ax.set_yticklabels([labs[i] for i in even_idx])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# load necessary packages\nlibrary(repsim)\n\n# set a random seed\nset.seed(1)\n\n# prepare the prototype\nX &lt;- as.matrix(scale(as.matrix(iris[sample(1:150, 50, replace = FALSE), 1:4])))\nY &lt;- as.matrix(scale(as.matrix(USArrests)))\nn   &lt;- nrow(X)\np_X &lt;- ncol(X)\np_Y &lt;- ncol(Y)\n\n# generate 10 of each by perturbation\nmats &lt;- vector(\"list\", length = 20L)\nfor (i in 1:10){\n  mats[[i]] &lt;- X + matrix(rnorm(n * p_X, sd = 1), nrow = n)\n}\nfor (j in 11:20){\n  mats[[j]] &lt;- Y + matrix(rnorm(n * p_Y, sd = 1), nrow = n)\n}\n\n# compute similarities\ncca_gcd   &lt;- cca(mats, summary_type = \"yanai\")\ncca_trace &lt;- cca(mats, summary_type = \"pillai\")\n\n# visualize: two heatmaps side by side\nlabs &lt;- paste0(\"rep \", 1:20)\npar(pty = \"s\", mfrow = c(1, 2))\n\nimage(cca_gcd[, 20:1], axes = FALSE, main = \"CCA: Yanai's GCD\")\naxis(1, seq(0, 1, length.out = 20), labels = labs, las = 2)\naxis(2, at = seq(0, 1, length.out = 20), labels = rev(labs), las = 2)\n\nimage(cca_trace[, 20:1], axes = FALSE, main = \"CCA: Pillai's Trace\")\naxis(1, seq(0, 1, length.out = 20), labels = labs, las = 2)\naxis(2, at = seq(0, 1, length.out = 20), labels = rev(labs), las = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\nGolub, Gene H., and Hongyuan Zha. 1995. “The Canonical Correlations of Matrix Pairs and Their Numerical Computation.” In Linear Algebra for Signal Processing, edited by Avner Friedman, Willard Miller, Adam Bojanczyk, and George Cybenko, 69:27–49. New York, NY: Springer New York.\n\n\nRaghu, Maithra, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein. 2017. “SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability.” In Proceedings of the 31st International Conference on Neural Information Processing Systems, 6078–87. NIPS’17. Red Hook, NY, USA: Curran Associates Inc.\n\n\nRamsay, J. O., Jos ten Berge, and G. P. H. Styan. 1984. “Matrix Correlation.” Psychometrika 49 (3): 403–23.",
    "crumbs": [
      "Overview",
      "CCA",
      "cca"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Measures of Representational Similarity in Python and R\n\n           \n\n\n\n\nrepsim provides representational similarity metrics implemented in C++ (Eigen), with thin bindings to Python (pybind11 + scikit-build-core) and R (RcppEigen).\n\nDot Product similarity (Kornblith et al., 2019)\nHSIC (Gretton et al., 2005) with linear / RBF (median, mean, dual-median)\n(Future) CKA, CCA (Yanai / Pillai), SVCCA\n\nUse the Install and Getting Started pages, or jump into the API."
  },
  {
    "objectID": "api/family_cca/SVCCA.html",
    "href": "api/family_cca/SVCCA.html",
    "title": "svcca",
    "section": "",
    "text": "Description\nCompute pairwise singular vector CCA (SVCCA) similarities between multiple representations (Raghu et al. 2017). SVCCA first mean-centers and denoises each representation via SVD, retaining components explaining a high fraction of variance at 99% threshold. Then, CCA is applied to the reduced representations, and the similarity is summarized with either Yanai’s GCD (Ramsay, ten Berge, and Styan 1984) or Pillai’s trace (Raghu et al. 2017).\n\n\nUsage\n\nPythonR\n\n\nrepsim.svcca(mats, summary_type = None)\n\n\nsvcca(mats, summary_type = NULL)\n\n\n\n\n\nArguments\n\nPythonR\n\n\n\nmats: sequence of array-like, length \\(M\\) List or tuple of M data representations, each of shape (n_samples, n_features_k). All matrices must share the same number of rows for matching samples. Each element can be a NumPy array or any object convertible to one via numpy.asarray.\nsummary_type: str, optional Summary statistic for canonical correlations. One of \"yanai\" and \"pillai\". Defaults to \"yanai\".\n\n\n\n\nmats: A list of length M containing data matrices of size (n_samples, n_features_k). All matrices must share the same number of rows for matching samples.\nsummary_type: Character scalar indicating the CCA summary statistic. One of \"yanai\" or \"pillai\". Defaults to \"yanai\" if NULL.\n\n\n\n\n\n\nReturns\n\nPythonR\n\n\n\nnumpy.ndarray\n\nArray of shape (M, M) of SVCCA summary similarities.\n\n\n\n\n\nmatrix\n\nAn (M, M) symmetric matrix of SVCCA summary similarities.\n\n\n\n\n\n\n\nExamples\n\nPythonR\n\n\n\n# | cache: true\n# load necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nimport repsim\n\n# set a random seed\nnp.random.seed(1)\n\n# prepare the prototype\niris = load_iris(as_frame=True).frame.iloc[:, :4]\nurl = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv\"\nusarrests = pd.read_csv(url, index_col=0)\n\nX = StandardScaler().fit_transform(iris.sample(50, random_state=1))\nY = StandardScaler().fit_transform(usarrests)\n\nn, p_X, p_Y = X.shape[0], X.shape[1], Y.shape[1]\n\n# generate 10 of each by perturbation\nmats = []\nfor _ in range(10):\n    mats.append(X + np.random.normal(scale=1.0, size=(n, p_X)))\nfor _ in range(10):\n    mats.append(Y + np.random.normal(scale=1.0, size=(n, p_Y)))\n\n# compute similarities\nsvcca_gcd = repsim.svcca(mats, summary_type=\"yanai\")\nsvcca_trace = repsim.svcca(mats, summary_type=\"pillai\")\n\n# visualize: two heatmaps side by side\nfig, axes = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\ntitles = [\"SVCCA: Yanai's GCD\", \"SVCCA: Pillai's Trace\"]\nmats_show = [svcca_gcd, svcca_trace]\n\nlabs = [f\"rep {i}\" for i in range(1, 21)]\neven_idx = list(range(1, 20, 2))\n\nfor ax, mat, title in zip(axes, mats_show, titles):\n    im = ax.imshow(mat, origin=\"upper\")\n    ax.set_title(title)\n    _ = ax.set_xticks(even_idx)\n    _ = ax.set_xticklabels([labs[i] for i in even_idx], rotation=90)\n    _ = ax.set_yticks(even_idx)\n    _ = ax.set_yticklabels([labs[i] for i in even_idx])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# load necessary packages\nlibrary(repsim)\n\n# set a random seed\nset.seed(1)\n\n# prepare the prototype\nX &lt;- as.matrix(scale(as.matrix(iris[sample(1:150, 50, replace = FALSE), 1:4])))\nY &lt;- as.matrix(scale(as.matrix(USArrests)))\nn   &lt;- nrow(X)\np_X &lt;- ncol(X)\np_Y &lt;- ncol(Y)\n\n# generate 10 of each by perturbation\nmats &lt;- vector(\"list\", length = 20L)\nfor (i in 1:10){\n  mats[[i]] &lt;- X + matrix(rnorm(n * p_X, sd = 1), nrow = n)\n}\nfor (j in 11:20){\n  mats[[j]] &lt;- Y + matrix(rnorm(n * p_Y, sd = 1), nrow = n)\n}\n\n# compute similarities\nsvcca_gcd   &lt;- svcca(mats, summary_type = \"yanai\")\nsvcca_trace &lt;- svcca(mats, summary_type = \"pillai\")\n\n# visualize: two heatmaps side by side\nlabs &lt;- paste0(\"rep \", 1:20)\npar(pty = \"s\", mfrow = c(1, 2))\n\nimage(svcca_gcd[, 20:1], axes = FALSE, main = \"SVCCA: Yanai's GCD\")\naxis(1, seq(0, 1, length.out = 20), labels = labs, las = 2)\naxis(2, at = seq(0, 1, length.out = 20), labels = rev(labs), las = 2)\n\nimage(svcca_trace[, 20:1], axes = FALSE, main = \"SVCCA: Pillai's Trace\")\naxis(1, seq(0, 1, length.out = 20), labels = labs, las = 2)\naxis(2, at = seq(0, 1, length.out = 20), labels = rev(labs), las = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\nRaghu, Maithra, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein. 2017. “SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability.” In Proceedings of the 31st International Conference on Neural Information Processing Systems, 6078–87. NIPS’17. Red Hook, NY, USA: Curran Associates Inc.\n\n\nRamsay, J. O., Jos ten Berge, and G. P. H. Styan. 1984. “Matrix Correlation.” Psychometrika 49 (3): 403–23.",
    "crumbs": [
      "Overview",
      "CCA",
      "svcca"
    ]
  },
  {
    "objectID": "api/family_cca/PWCCA.html",
    "href": "api/family_cca/PWCCA.html",
    "title": "pwcca",
    "section": "",
    "text": "Description\nThis function computes pairwise projection-weighted CCA (PWCCA) similarities between multiple representations (Morcos, Raghu, and Bengio 2018). PWCCA reweights canonical directions by the magnitude of each representation’s projection onto those directions, emphasizing components that are most used by the representation.\n\n\nUsage\n\nPythonR\n\n\nrepsim.pwcca(mats)\n\n\npwcca(mats)\n\n\n\n\n\nArguments\n\nPythonR\n\n\n\nmats: sequence of array-like, length \\(M\\) List or tuple of M data representations, each of shape (n_samples, n_features_k). All matrices must share the same number of rows for matching samples. Each element can be a NumPy array or any object convertible to one via numpy.asarray.\n\n\n\n\nmats: A list of length M containing data matrices of size (n_samples, n_features_k). All matrices must share the same number of rows for matching samples.\n\n\n\n\n\n\nReturns\n\nPythonR\n\n\n\nnumpy.ndarray\n\nArray of shape (M, M) of PWCCA similarities.\n\n\n\n\n\nmatrix\n\nAn (M, M) symmetric matrix of PWCCA similarities.\n\n\n\n\n\n\n\nExamples\n\nPythonR\n\n\n\n# | cache: true\n# load necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nimport repsim\n\n# set a random seed\nnp.random.seed(1)\n\n# prepare the prototype\niris = load_iris(as_frame=True).frame.iloc[:, :4]\nurl = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv\"\nusarrests = pd.read_csv(url, index_col=0)\n\nX = StandardScaler().fit_transform(iris.sample(50, random_state=1))\nY = StandardScaler().fit_transform(usarrests)\n\nn, p_X, p_Y = X.shape[0], X.shape[1], Y.shape[1]\n\n# generate 10 of each by perturbation\nmats = []\nfor _ in range(10):\n    mats.append(X + np.random.normal(scale=1.0, size=(n, p_X)))\nfor _ in range(10):\n    mats.append(Y + np.random.normal(scale=1.0, size=(n, p_Y)))\n\n# compute similarities\nout_pwcca = repsim.pwcca(mats)\n\n# visualize\nfig, ax = plt.subplots(figsize=(8, 4), constrained_layout=True)\nlabs = [f\"rep {i}\" for i in range(1, 21)]\neven_idx = list(range(1, 20, 2))\n\nim = ax.imshow(out_pwcca, origin=\"upper\")\nax.set_title(\"PWCCA\")\n\nText(0.5, 1.0, 'PWCCA')\n\n_ = ax.set_xticks(even_idx)\n_ = ax.set_xticklabels([labs[i] for i in even_idx], rotation=90)\n_ = ax.set_yticks(even_idx)\n_ = ax.set_yticklabels([labs[i] for i in even_idx])    \n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# load necessary packages\nlibrary(repsim)\n\n# set a random seed\nset.seed(1)\n\n# prepare the prototype\nX &lt;- as.matrix(scale(as.matrix(iris[sample(1:150, 50, replace = FALSE), 1:4])))\nY &lt;- as.matrix(scale(as.matrix(USArrests)))\nn   &lt;- nrow(X)\np_X &lt;- ncol(X)\np_Y &lt;- ncol(Y)\n\n# generate 10 of each by perturbation\nmats &lt;- vector(\"list\", length = 20L)\nfor (i in 1:10){\n  mats[[i]] &lt;- X + matrix(rnorm(n * p_X, sd = 1), nrow = n)\n}\nfor (j in 11:20){\n  mats[[j]] &lt;- Y + matrix(rnorm(n * p_Y, sd = 1), nrow = n)\n}\n\n# compute similarities\nout_pwcca &lt;- pwcca(mats)\n\n# visualize: two heatmaps side by side\nlabs &lt;- paste0(\"rep \", 1:20)\npar(pty = \"s\")\n\nimage(out_pwcca[, 20:1], axes = FALSE, main = \"PWCCA\")\naxis(1, seq(0, 1, length.out = 20), labels = labs, las = 2)\naxis(2, at = seq(0, 1, length.out = 20), labels = rev(labs), las = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\nMorcos, Ari S., Maithra Raghu, and Samy Bengio. 2018. “Insights on Representational Similarity in Neural Networks with Canonical Correlation.” In Proceedings of the 32nd International Conference on Neural Information Processing Systems, 5732–41. NIPS’18. Red Hook, NY, USA: Curran Associates Inc.",
    "crumbs": [
      "Overview",
      "CCA",
      "pwcca"
    ]
  },
  {
    "objectID": "api/family_alignment/LinearRegression.html",
    "href": "api/family_alignment/LinearRegression.html",
    "title": "lin_reg",
    "section": "",
    "text": "Description\nCompute pairwise linear-regression fit between multiple representations (Kornblith et al. 2019). After centering, for each pair, a least-squares map is used to assess how well one representation predicts the other, and the result is symmetrized.\n\n\nUsage\n\nPythonR\n\n\nrepsim.lin_reg(mats)\n\n\nlin_reg(mats)\n\n\n\n\n\nArguments\n\nPythonR\n\n\n\nmats: sequence of array-like, length \\(M\\) List or tuple of M data representations, each of shape (n_samples, n_features_k). All matrices must share the same number of rows for matching samples. Each element can be a NumPy array or any object convertible to one via numpy.asarray.\n\n\n\n\nmats: A list of length M containing data matrices of size (n_samples, n_features_k). All matrices must share the same number of rows for matching samples.\n\n\n\n\n\n\nReturns\n\nPythonR\n\n\n\nnumpy.ndarray\n\nArray of shape (M, M) of symmetric similarities.\n\n\n\n\n\nmatrix\n\nAn (M, M) symmetric matrix of similarities.\n\n\n\n\n\n\n\nExamples\n\nPythonR\n\n\n\n# | cache: true\n# load necessary packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nimport repsim\n\n# set a random seed\nnp.random.seed(1)\n\n# prepare the prototype\niris = load_iris(as_frame=True).frame.iloc[:, :4]\nurl = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv\"\nusarrests = pd.read_csv(url, index_col=0)\n\nX = StandardScaler().fit_transform(iris.sample(50, random_state=1))\nY = StandardScaler().fit_transform(usarrests)\n\nn, p_X, p_Y = X.shape[0], X.shape[1], Y.shape[1]\n\n# generate 10 of each by perturbation\nmats = []\nfor _ in range(10):\n    mats.append(X + np.random.normal(scale=1.0, size=(n, p_X)))\nfor _ in range(10):\n    mats.append(Y + np.random.normal(scale=1.0, size=(n, p_Y)))\n\n# compute similarities\nout_R2 = repsim.pwcca(mats)\n\n# visualize\nfig, ax = plt.subplots(figsize=(8, 4), constrained_layout=True)\nlabs = [f\"rep {i}\" for i in range(1, 21)]\neven_idx = list(range(1, 20, 2))\n\nim = ax.imshow(out_R2, origin=\"upper\")\nax.set_title(\"Linear Regression\")\n\nText(0.5, 1.0, 'Linear Regression')\n\n_ = ax.set_xticks(even_idx)\n_ = ax.set_xticklabels([labs[i] for i in even_idx], rotation=90)\n_ = ax.set_yticks(even_idx)\n_ = ax.set_yticklabels([labs[i] for i in even_idx])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# load necessary packages\nlibrary(repsim)\n\n# set a random seed\nset.seed(1)\n\n# prepare the prototype\nX &lt;- as.matrix(scale(as.matrix(iris[sample(1:150, 50, replace = FALSE), 1:4])))\nY &lt;- as.matrix(scale(as.matrix(USArrests)))\nn   &lt;- nrow(X)\np_X &lt;- ncol(X)\np_Y &lt;- ncol(Y)\n\n# generate 10 of each by perturbation\nmats &lt;- vector(\"list\", length = 20L)\nfor (i in 1:10){\n  mats[[i]] &lt;- X + matrix(rnorm(n * p_X, sd = 1), nrow = n)\n}\nfor (j in 11:20){\n  mats[[j]] &lt;- Y + matrix(rnorm(n * p_Y, sd = 1), nrow = n)\n}\n\n# compute similarities\nout_R2 &lt;- pwcca(mats)\n\n# visualize: two heatmaps side by side\nlabs &lt;- paste0(\"rep \", 1:20)\npar(pty = \"s\")\n\nimage(out_R2[, 20:1], axes = FALSE, main = \"Linear Regression\")\naxis(1, seq(0, 1, length.out = 20), labels = labs, las = 2)\naxis(2, at = seq(0, 1, length.out = 20), labels = rev(labs), las = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\n\nKornblith, Simon, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton. 2019. “Similarity of Neural Network Representations Revisited.” In International Conference on Machine Learning, 3519–29. PMLR.",
    "crumbs": [
      "Overview",
      "Alignment",
      "lin_reg"
    ]
  }
]